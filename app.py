import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from streamlit.proto.DataFrame_pb2 import DataFrame
import seaborn as sns

from numpy.random import random_integers
from scipy.sparse.construct import rand

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

import io 

import SessionState
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances_argmin_min
from kneed import KneeLocator
from mpl_toolkits.mplot3d import Axes3D
from app_aux import *
import time
from sklearn import linear_model 
from sklearn import model_selection
from sklearn.metrics import classification_report 
import math

#from sklearn.metrics import confusion_matrix
#from sklearn.metrics import accuracy_score
#from PIL import Image
#from random import randint
#from session_state import get_session_state
#from apyori import apriori
#from scipy.spatial.distance import cdist

#sudo apt-get install python3-tk
#datos = None
#datos_subido = None
#st.caching.clear_cache()

PAGES = (
    "游뱄 Inicio",
    "游 Carga de datos",
    "游닀 An치lisis exploratorio de datos",
    "游늵 An치lisis de componentes principales",
    "游놁 Clustering particional",
    "游댍 Clasificaci칩n",
    "游댍 Prueba de modelo RL"
)

global session_state
session_state = SessionState.get(datosEDA = 0, datos = None, valor_reemplazo = 0, widgetKey = 0)
session_state_1 = SessionState.get(datosPCA = 0, clustering_sns_pairplot = None)
session_state_1.clustering_sns_pairplot = None
def pagina_inicio():

    st.title('Bienvenid@ a mi Peque침a Herramienta de Miner칤a de Datos (PHMD)')

    my_bar = st.progress(0)
    for percent_complete in range(100):
        time.sleep(0.0005)
        my_bar.progress(percent_complete + 1)

    chart_data = pd.DataFrame(
        np.random.randn(50, 3),
        columns=['a', 'b', 'c'])
    st.line_chart(chart_data)
    

    st.subheader("Esta herramienta fue creada con 仇벒잺 por Gustavo Jim칠nez, alumno de la Facultad de Ingenier칤a de la Universidad Nacional Aut칩noma de M칠xico.")
    st.write("_Para comenzar el an치lisis de datos puedes dar clic en alguna de las opciones de la barra de navegaci칩n._")

def pagina_carga_datos():

    st.title('Carga y modificaci칩n de datos')
    st.header("Importaci칩n de datos")
    st.write("1. Lectura de datos")

    if(st.radio("쮺ontiene Header?",("Si","No"),key="1")=="No"):
        datos_header = None
    else:
        datos_header = 0

    datos_sep = st.text_input("Separaci칩n de los datos: ", value=",")
    datos_subido = st.file_uploader("Escoge el archivo que quieres analizar: ", type = ['csv', 'xlsx', 'xls'])

    if(datos_subido is not None):
        with st.spinner('Procesando datos...'):
            datos_csv = pd.read_csv(datos_subido, header=datos_header, sep=datos_sep)
            session_state.datos_iniciales = pd.DataFrame(datos_csv)
            #st.write(session_state.datos_iniciales)
            session_state.datos_iniciales_0 = session_state.datos_iniciales
            session_state.widgetKey = session_state.widgetKey + 1
        st.success('춰Hecho!')
        session_state.datos = session_state.datos_iniciales
    
    if(session_state.datos is None):
        st.error("Por favor, sube un archivo")

    try:

        datos_sep = 0
        datos_subido = None
        #datos = 0
        datos_csv = 0

        columnas = st.multiselect(
            "Escoge las columnas que utilizar치s para los algoritmos: ", list(session_state.datos_iniciales_0.columns), list(session_state.datos.columns), key="ms_datos_1"
        )
        if not columnas:
            st.error("Por favor escoge al menos una columna a analizar")
        
        st.write("Datos iniciales")
        st.write(session_state.datos_iniciales_0[columnas])

        st.success("춰Ya puedes continuar con otra opci칩n!")

        st.header("Reemplazar valores en alguna columna")
        columnaClasificacion = st.selectbox(
            "Escoge la columa a reemplazar: ", columnas, index=0
        )

        with st.spinner("Recargando datos"):
            session_state.datos = session_state.datos_iniciales[columnas]

        if not columnaClasificacion:
            st.error("No se ha seleccionado ninguna columna para sustituir valores")
        else:
            valorSustitucionClasificacionReemplazar = st.text_input("Inserta [valor_a_reemplazar] y seguido de una coma [valor_nuevo]: ")

            if(valorSustitucionClasificacionReemplazar==""):
                st.warning("Ning칰n valor insertado. Al dar enter se reemplazar치 el valor")
            else:
                valores = valorSustitucionClasificacionReemplazar.split(",")
                if "," not in valorSustitucionClasificacionReemplazar:
                    st.error("Por favor, inserta una coma entre valor a reemplazar y valor nuevo")
                else:
                        #session_state.datos_iniciales = session_state.datos_iniciales[columnas]
                    session_state.datos[columnaClasificacion] = session_state.datos[columnaClasificacion].replace(valores[0], valores[1])
                    session_state.datos_iniciales[columnaClasificacion] = session_state.datos[columnaClasificacion].replace(valores[0], valores[1])
                    st.warning("Al dar enter se reemplazar치 el valor")
                    st.success("춰Datos modificados!")
        st.write("Datos le칤dos con datos modificados, **estos datos ser치n los que se usen en las dem치s pesta침as**")
        st.write(session_state.datos)
                    
    except Exception as e:
        st.write("Sin datos.")
        #st.exception(e)


def pagina_analisisExploratorioDeDatos():

    st.title('An치lisis Exploratorio de Datos (EDA)')

    datosEDA = session_state.datos

    if(datosEDA is not None):
        with st.spinner('Recargando datos...'):
            st.header("Datos")
            st.write("1. Visualizaci칩n de datos")
            st.write("Datos le칤dos")
            st.write(datosEDA)
        st.success('춰Hecho!')
        st.warning("Si necesitas editar alguna columna de tu dataset, dir칤gete a la opci칩n de carga de datos")

    try:
        VariableValoresAtipicos = st.multiselect(
                "Escoge las columnas de tu elecci칩n para visualizar valores at칤picos: ", 
                pd.DataFrame(datosEDA).select_dtypes(include=np.number).columns.tolist(), 
                pd.DataFrame(datosEDA).select_dtypes(include=np.number).columns.tolist()
            )
        if not VariableValoresAtipicos:
            st.error("Por favor escoge al menos una columna a analizar para valores at칤picos. Algunas columnas no se muestran por no ser num칠ricas")
        else:
            if st.button("Iniciar ejecuci칩n",key="b_1"):
                st.header("Descripci칩n de la estructura de los datos")
                st.write("1. Dimensiones de la data")
                st.write("Renglones:")
                datosEDA.shape[0]
                st.write("Columnas:")
                datosEDA.shape[1]
                st.write("2. Tipos de dato de las variables")
                datosEDA.dtypes

                st.header("Identificaci칩n de datos faltantes")
                buffer = io.StringIO() 
                datosEDA.info(buf=buffer)
                info = buffer.getvalue()
                st.text(info)

                st.header("Detecci칩n de valores at칤picos")
                st.write("1. Distribuci칩n de variables num칠ricas")
                datosEDA.hist(figsize=(14,14), xrot=45)
                st.set_option('deprecation.showPyplotGlobalUse', False)
                st.pyplot()

                st.write("2. Resumen estad칤stico de variables num칠ricas")
                st.write(datosEDA.describe())

                st.write("3. Diagramas para detectar posibles valores at칤picos")
                with st.spinner('Procesando diagrama de caja...'):
                    for col in VariableValoresAtipicos:
                        with st_stdout("info"):
                            print("Diagrama de cajas y bigote para "+str(col))
                        sns.boxplot(col, data=datosEDA)
                        plt.show()
                        st.pyplot()
                st.success('춰Hecho!')
                
                try:
                    st.write("4. Distribuci칩n de variables categ칩ricas")
                    st.write(datosEDA.describe(include='object'))
                    
                    with st.spinner('Procesando histograma...'):
                        for col in datosEDA.select_dtypes(include='object'):
                            if datosEDA[col].nunique()<10:
                                st.write((datosEDA.groupby(col).agg(['mean'])))
                                sns.countplot(y=col, data=datosEDA)
                                plt.show()
                                st.pyplot()
                    st.success('춰Hecho!')

                    # for col in datosEDA.select_dtypes(include='object'):
                    #     if datosEDA[col].nunique() < 10:
                    #         st.write((datosEDA.groupby(col).agg(['mean'])))
                
                except Exception as e:
                    st.warning("Algunos datos no se muestran por el tipo de datos en el dataset")
                    ##st.exception(e)

                st.header("Identificaci칩n de relaciones entre pares de variables")
                st.write("1. Matriz de correlaciones")
                st.write(datosEDA.corr())
                st.write("2. Mapa de calor de la matriz de correlaciones")
                plt.figure(figsize=(14,14))
                sns.heatmap(datosEDA.corr(), cmap='RdBu_r', annot=True)
                plt.show()
                st.pyplot()
    except Exception as e:
        st.error("Datos no cargados o incompatibles, por favor dir칤gete a la pesta침a de carga de datos")
        #st.exception(e)

def pagina_analisisComponentesPrincipales():
 
    #"""
    # Componentes principales
    #En esta p치gina se visualizan las componentes principales de un set de datos.
    #"""

    st.title('An치lisis de Componentes Principales (PCA)')

    datosPCA = session_state.datos

    if(datosPCA is not None):
        with st.spinner('Recargando datos...'):
            st.header("Datos")
            st.write("1. Visualizaci칩n de datos")
            st.write("Datos le칤dos")
            st.write(datosPCA)
        st.success('춰Hecho!')
        st.warning("Si necesitas editar alguna columna de tu dataset, dir칤gete a la opci칩n de carga de datos")
        st.warning("Este algoritmo funciona con datos num칠ricos")

        if st.button("Iniciar ejecuci칩n"):

            datosPCA = pd.DataFrame(datosPCA).select_dtypes(include=np.number).replace(np.NaN,0)
            st.header("Estandarizaci칩n de los datos")
            normalizar = StandardScaler()
            normalizar.fit(datosPCA)
            datosPCA_normalizada = normalizar.transform(datosPCA)
            st.write("1. Dimensiones de la tabla")
            st.write("Renglones:")
            datosPCA_normalizada.shape[0]
            st.write("Columnas:")
            datosPCA_normalizada.shape[1]
            #st.write(datosPCA_normalizada.shape)
            st.write("2. Datos normalizados")
            st.write(pd.DataFrame(datosPCA_normalizada, columns=datosPCA.columns))
            
            st.header("Matriz de covarianzas y correlaciones, varianza y componentes")
            Componentes = PCA(n_components=len(datosPCA.columns))
            Componentes.fit(datosPCA_normalizada)
            X_Comp = Componentes.transform(datosPCA_normalizada)
            st.write(pd.DataFrame(X_Comp))

            st.header("Elecci칩n del n칰mero de componentes principales (eigen-vectores)")
            Varianza = Componentes.explained_variance_ratio_
            st.write("Eigenvalues:",Varianza)
            st.write("Varianza acumulada: ",sum(Varianza[0:5]))

            plt.plot(np.cumsum(Componentes.explained_variance_ratio_))
            plt.xlabel("N칰mero de componentes")
            plt.ylabel("Varianza acumulada")
            plt.grid()
            plt.show()
            st.set_option('deprecation.showPyplotGlobalUse', False)
            st.pyplot()

            st.header("An치lisis de proporci칩n de relevancias (cargas)")
            st.write("Se revisan los valores absolutos de los componentes principales seleccionados. Cuanto mayor sea el valor absoluto, m치s importante es esa variable en el componente principal.")
            st.write(pd.DataFrame(abs(Componentes.components_),columns=datosPCA.columns))
            #CargasComponentes = pd.DataFrame(Componentes.components_, columns=datosPCA.columns)
            #st.write(CargasComponentes)
            #CargasComponentes = pd.DataFrame(abs(Componentes.components_), columns=datosPCA.columns)
            #st.write(CargasComponentes)
    else:
        st.error("Datos no cargados o incompatibles, por favor dir칤gete a la pesta침a de carga de datos")
        ##st.exception(e)

def pagina_clustering():
    st.title('Clustering particional')
    try:
        if(session_state.datos is not None):
            st.header("Datos")
            st.write("1. Visualizaci칩n de datos")
            with st.spinner("Recargando datos"):
                session_state.datos
            st.success("춰Hecho!")
            st.warning("Si necesitas editar alguna columna de tu dataset, dir칤gete a la opci칩n de carga de datos")
            st.warning("Este algoritmo funciona con datos num칠ricos")
            st.header("Selecci칩n de caracter칤sticas")
            
            st.write("Comparaci칩n de relaci칩n entre variables")

        #while True:

        session_state.numericos = pd.DataFrame(session_state.datos).select_dtypes(include=np.number).replace(np.NaN,0)


        columna0 = st.selectbox("Selecciona la columna principal a comparar para los ejes: ", session_state.numericos.columns, key="15")
        clustering_x = st.selectbox("Selecciona la primer variable:", session_state.numericos.columns, key="4")
        clustering_y = st.selectbox("Selecciona la segunda variable:", session_state.numericos.columns, key="5")
        st.set_option('deprecation.showPyplotGlobalUse', False)
        sns.scatterplot(x=clustering_x,y=clustering_y,data=session_state.numericos,hue=columna0)
        plt.title("Gr치fico de dispersi칩n")
        plt.xlabel(clustering_x)
        plt.ylabel(clustering_y)
        plt.show()
        st.pyplot()

        columna = 0
        columna_tmp = columna
        columna = st.selectbox("Selecciona la columna principal a comparar para generar la matriz de correlaciones: ", session_state.numericos.columns, key="6")
        
        if(st.button("Iniciar ejecuci칩n", key="bt_clustering")):
            with st.spinner('Procesando matriz...'):
                if(session_state_1.clustering_sns_pairplot == None  or columna_tmp != columna):
                    clustering_sns_pairplot = sns.pairplot(session_state.numericos, hue=columna)
                    session_state_1.clustering_sns_pairplot = clustering_sns_pairplot
                plt.show()
                st.set_option('deprecation.showPyplotGlobalUse', False)
                st.pyplot()
            st.success('춰Hecho!')

            st.write("Matriz de correlaciones")
            datosPCA_corr = session_state.numericos.corr(method="pearson")
            datosPCA_corr
            st.write("Mapa de calor")
            plt.figure(figsize=(14,7))
            MatrizInf = np.triu(datosPCA_corr)
            sns.heatmap(datosPCA_corr, cmap="RdBu_r", annot=True, mask=MatrizInf)
            plt.show()
            st.pyplot()

            st.header("Variables utilizadas en el an치lisis")
            columnasPCA = st.multiselect(
                "Se enlistan las columnas que se utilizan:", list(session_state.numericos.columns), list(session_state.numericos.columns)
            )
            if not columnasPCA:
                st.error("Por favor escoge al menos una columna a analizar")
            else:
                datosPCA = session_state.numericos[columnasPCA]

            datosPCA
            st.warning("Recuerda que si necesitas modificar tus datos debes dirigirte a la pesta침a de carga de datos")

            st.header("Algoritmo K-means")
            SSE=[]
            for i in range(2,12):
                km=KMeans(n_clusters=i,random_state=0)
                km.fit(datosPCA)
                SSE.append(km.inertia_)

            #Se grafica SSE en funci칩n de k
            plt.figure(figsize=(10,7))
            plt.plot(range(2,12),SSE,marker="o")
            plt.xlabel("Cantidad de cl칰sters *k*")
            plt.ylabel("SSE")
            plt.title("M칠todo del codo")
            plt.show()
            st.pyplot()

            kl = KneeLocator(range(2,12),SSE,curve="convex",direction="decreasing")
            st.write("N칰mero de cl칰sters con mayor convergencia")
            st.text(kl.elbow)

            st.write("Cl칰ster al que pertenece cada registro")
            MParticional = KMeans(n_clusters=4, random_state=0).fit(session_state.numericos)
            MParticional.predict(session_state.numericos)
            MParticional.labels_

            st.write("Se a침ade la columna de n칰mero de cl칰ster de cada registro")
            datosPCA["clusterP"] = MParticional.labels_
            datosPCA

            st.write("N칰mero de registros en cada cl칰ster")
            st.write(datosPCA.groupby(["clusterP"])["clusterP"].count())

            st.write("Gr치fica para mostrar cl칰steres por color")
            plt.figure(figsize=(10,7))
            plt.scatter(datosPCA.iloc[:,0], datosPCA.iloc[:,1],c=MParticional.labels_,cmap="rainbow")
            plt.show()
            st.pyplot()

            st.write("Media de los registros en cada cl칰ster")
            CentroidesP = MParticional.cluster_centers_
            st.write(pd.DataFrame(CentroidesP.round(4),columns=datosPCA.columns[0:len(datosPCA.columns)-1]))
            #from plotnine import *

            plt.rcParams["figure.figsize"] = (10,7)
            plt.style.use("ggplot")
            colores=["red","blue","green","yellow"]
            asignar=[]
            for row in MParticional.labels_:
                asignar.append(colores[row])

            st.write("Gr치fica 3D de la clasificaci칩n de los registros")

            fig = plt.figure()
            ax = Axes3D(fig)
            ax.scatter(datosPCA.iloc[:,0],datosPCA.iloc[:,1],datosPCA.iloc[:,2],marker="o",c=asignar,s=60)
            ax.scatter(CentroidesP[:,0],CentroidesP[:,1],CentroidesP[:,2],marker="*",c=colores,s=1000)
            plt.show()
            st.pyplot()
            #st.pyplot(ggplot.draw(fig))

            st.write("Registros m치s cercanos al centroide")
            Cercanos,_ = pairwise_distances_argmin_min(MParticional.cluster_centers_, session_state.numericos)
            Cercanos

        #st.write("1. Dimensiones de la data")
    except Exception as e:
        st.error("Datos no cargados o incompatibles, por favor dir칤gete a la pesta침a de carga de datos.")
        #st.exception(e)

#@st.cache(suppress_st_warning=True)
#def clustering_cache_sns(sns_data, columna, columna_tmp):

def pagina_clasificacion():

    datosClasificacion = session_state.datos
    st.title('Clasificaci칩n: Regresi칩n Log칤stica')

    try:
        if(datosClasificacion is not None):
            with st.spinner('Recargando datos...'):
                st.header("Datos")
                st.write("1. Visualizaci칩n de datos")
                st.write("Datos le칤dos")
                st.write(datosClasificacion)
            st.success('춰Hecho!')

            st.warning("Si necesitas editar alguna columna de tu dataset, dir칤gete a la opci칩n de carga de datos")

            st.header("Variable predictora")
            columnaClasificacion = st.selectbox(
                "Escoge la variable predictora: ", list(session_state.datos.columns), index=0
            )
            st.write(datosClasificacion.groupby(columnaClasificacion).size())

            st.warning("Recuerda que el algoritmo funciona con valores 1-0, es necesario que hagas estos ajustes desde la pesta침a de carga de datos")
            
            st.header("Selecci칩n de caracter칤sticas")
            
            st.write("Comparaci칩n de relaci칩n entre variables")

            #while True:
            st.set_option('deprecation.showPyplotGlobalUse', False)
            clustering_x = st.selectbox("Selecciona la primer variable:", session_state.datos.columns, key="12")
            clustering_y = st.selectbox("Selecciona la segunda variable:", session_state.datos.columns, key="13")
            sns.scatterplot(x=clustering_x,y=clustering_y,data=session_state.datos,hue=columnaClasificacion)
            plt.title("Gr치fico de dispersi칩n")
            plt.xlabel(clustering_x)
            plt.ylabel(clustering_y)
            plt.show()
            st.pyplot()

            if(st.button("Iniciar ejecuci칩n",key="b_2")):

                columna = 0
                columna_tmp = columna

                st.write("Matriz de correlaciones")
                datos_corr = session_state.datos.corr(method="pearson")
                datos_corr
                st.write("Mapa de calor")
                plt.figure(figsize=(14,7))
                MatrizInf = np.triu(datos_corr)
                sns.heatmap(datos_corr, cmap="RdBu_r", annot=True, mask=MatrizInf)
                plt.show()
                st.pyplot()
                
                st.warning("Si tienes que realizar eliminaci칩n de columnas, recuerda hacerlo en la pesta침a de carga de datos")
                X=session_state.datos.drop(columnaClasificacion, axis=1)
                Y=session_state.datos[columnaClasificacion]

                st.header("Aplicaci칩n del algoritmo")
                Clasificacion = linear_model.LogisticRegression()
                seed=1234
                X_train,X_validation,Y_train,Y_validation=model_selection.train_test_split(X,Y,test_size=0.2,random_state=seed,shuffle=True)

                pd.DataFrame(X_train)
                pd.DataFrame(Y_train)
                
                st.write("Entrenamiento del modelo a partir de los datos de entrada")
                st.write(Clasificacion.fit(X_train,Y_train))

                st.write("Predicciones probabil칤sticas")
                Probabilidad = Clasificacion.predict_proba(X_train)
                st.write(pd.DataFrame(Probabilidad))

                st.write("Predicciones con clasificaci칩n final")
                Predicciones = Clasificacion.predict(X_train)
                st.write(pd.DataFrame(Predicciones))

                # st.write("Exactitud")
                exactitud = Clasificacion.score(X_train,Y_train)
                # st.info(exactitud)

                st.header("Validaci칩n del modelo")

                st.write("Matriz de clasificaci칩n")
                PrediccionesNuevas = Clasificacion.predict(X_validation)
                confusion_matrix = pd.crosstab(Y_validation.ravel(), PrediccionesNuevas, rownames=["Real"], colnames=["Clasificaci칩n"])
                confusion_matrix

                st.write("Reporte de la clasificaci칩n")
                with st_stdout("info"):
                    print(classification_report(Y_validation,PrediccionesNuevas))

                st.write("Intercepto")
                st.write(Clasificacion.intercept_)
                st.write("Coeficientes")
                st.write(Clasificacion.coef_)

                session_state.modeloRL = Clasificacion.coef_
                session_state.interceptoRL = Clasificacion.intercept_
                session_state.datosRL = X
                session_state.exactitudRL = exactitud

                with st_stdout("info"):
                    for i in range(len(session_state.datosRL.columns)):
                        print("{0:s} tiene una carga de: **{1:.3f}**\n".format(session_state.datosRL.columns[i],float(session_state.modeloRL[0,i])))
                with st_stdout("info"):
                    print("La exactitud del modelo es: **{0:.2f}%**".format(float(session_state.exactitudRL)*100))

                st.success("춰Se ha copiado el modelo predictivo! Dir칤gete a la pesta침a de prueba de modelo RL para insertar datos")
        else:
            st.error("Datos no cargados o incompatibles, por favor dir칤gete a la pesta침a de carga de datos.")
    except Exception as e:
        st.error("Datos no cargados o incompatibles, por favor dir칤gete a la pesta침a de carga de datos.")
        #st.exception(e)

def pagina_prueba_modelo():
    st.title('Prueba del modelo de Clasificaci칩n RL')
    st.header("Modelo actual")
    st.write("Coeficientes:")

    try:
        with st_stdout("info"):
            for i in range(len(session_state.datosRL.columns)):
                print("{0:s} tiene una carga de: **{1:.3f}**\n".format(session_state.datosRL.columns[i],float(session_state.modeloRL[0,i])))
        with st_stdout("info"):
            print("La exactitud del modelo es: **{0:.2f}%**".format(float(session_state.exactitudRL)*100))

        botonesRL = []

        st.header("Prueba del modelo")
        st.write("Inserta los valores del paciente: ")

        id = st.text_input("ID del paciente",value="0", key="tx")

        for i in range(len(session_state.datosRL.columns)):
            botonesRL.append(st.text_input(session_state.datosRL.columns[i],value="",key="tx_"+str(i)))

        if(st.button("Predecir c치ncer en paciente")):
            suma = 0
            for i in range(len(session_state.datosRL.columns)):
                suma = suma + (float(botonesRL[i])*float(session_state.modeloRL[0,i]))
            diagnosticoRL = 1/(1+math.e**(-(session_state.interceptoRL+suma)))

            if(diagnosticoRL<=0.5):
                with st_stdout("error"):
                    print("El paciente con ID **P-{0:s}** es diagnosticado con c치ncer maligno".format(id))
            else:
                with st_stdout("success"):
                    print("El paciente con ID **P-{0:s}** es diagnosticado con c치ncer benigno".format(id))
    except Exception as e:
        st.error("Datos no cargados o incompatibles, por favor dir칤gete a la pesta침a de carga de datos. Si ya lo has hecho, dir칤gete a clasificaci칩n para generar el modelo de predicci칩n")
        st.warning("Verifica que los datos insertados sean num칠ricos")
        #st.exception(e)

def main():

    st.set_page_config(
        page_title="PHMD",
        page_icon="游뱄",
        layout="centered",
        initial_sidebar_state="auto",
    )

    #"""Main function of the App"""
    st.sidebar.title("游리 Barra de navegaci칩n")
    selection = st.sidebar.radio("游댱 Da clic en la funci칩n que te gustar칤a utilizar: ", PAGES)

    if(selection == "游닀 An치lisis exploratorio de datos"):
        pagina_analisisExploratorioDeDatos()

    elif(selection == "游뱄 Inicio"):
        pagina_inicio()

    elif(selection == "游 Carga de datos"):
        pagina_carga_datos()

    elif(selection == "游늵 An치lisis de componentes principales"):
        pagina_analisisComponentesPrincipales()

    elif(selection == "游놁 Clustering particional"):
        pagina_clustering()

    elif(selection == "游댍 Clasificaci칩n"):
        pagina_clasificacion()

    elif(selection == "游댍 Prueba de modelo RL"):
        pagina_prueba_modelo()
        
if __name__ == "__main__":
    main()